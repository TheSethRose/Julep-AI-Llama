# Julep AI w/ Llama

A Python application that integrates Julep AI with a custom Llama model endpoint, providing a flexible and powerful AI agent system with persistent memory and efficient caching.

## Features

- ğŸ¤– Custom Llama model integration via OpenAI-compatible API
- ğŸ’¾ Persistent storage with SQLite
- ğŸ§  Vector embeddings with ChromaDB
- âš¡ Fast caching with Redis
- ğŸ”’ Secure environment configuration
- ğŸ“ Comprehensive logging system

## Prerequisites

- Python 3.12+
- Redis server
- Git
- A Julep API key from [dev.julep.ai](https://dev.julep.ai)

## Installation & Setup

Please refer to [setup.md](setup.md) for detailed installation and configuration instructions.

## Project Structure

```
Julep-AI-Llama/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agent_config.example.yaml  # Template for agent configuration
â”‚   â”œâ”€â”€ agent_config.yaml         # Your custom agent config (git-ignored)
â”‚   â””â”€â”€ memory_config.yaml       # Memory settings
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ chromadb/           # Vector embeddings storage
â”‚   â”œâ”€â”€ logs/               # Application logs
â”‚   â””â”€â”€ julep.db            # SQLite database
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .env.example           # Environment template
â”œâ”€â”€ main.py               # Main application
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
```

## Development

### Code Style

This project follows:
- PEP 8 style guide
- Type hints throughout
- Google-style docstrings
- Black code formatting

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- [Julep AI](https://dev.julep.ai) for the agent framework
- The Llama model community
- All contributors to this project
